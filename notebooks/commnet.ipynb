{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CommNet\n",
    "\n",
    "- Learning communication **not** with manually-specified protocols but instead using backpropagation from the RL signal\n",
    "- Considers cooperative task between $J$ agents.\n",
    "- Can be viewed as a single large model\n",
    "\n",
    "Given a view of the state for all agents $s = \\{s_1,...,s_J\\}$, a controller maps states to actions $a = \\Phi(s)$ where $a = \\{a_1,...,a_J\\}$ is a concatenation of discrete actions.\n",
    "\n",
    "$\\Phi$ is made of modules $f^i$, whic are multi-layer neural networks. $i \\in \\{0,..,K\\}$ is the number of communication steps in the network.\n",
    "\n",
    "Each $f^i$ takes two input vectors for each agent $j$: hidden state $h^i_j$ and communication $c^i_j$ and outputs a vector $h_j^{i+1}$. In the case that $f$ is a single-layer nn, $h^{i+1}_j = \\sigma(C^i_j c^i_j + H^i_j h^i_j)$.\n",
    "\n",
    "First layer of NN is an encoder function $h^0_j = r(s_j)$. For most tasks, they say it is a single-layer NN. \n",
    "\n",
    "$c^0_j$ = 0 âˆ€ j$.\n",
    "\n",
    "Output of NN is a decoder $a_j \\sim q(h^K_j)$ that outputs a distribution oer the action space. Single layer NN with softmax output. \n",
    "\n",
    "## Variations\n",
    "- Only allow communication between agents within a certain range.\n",
    "- Create skip connection between input encoding $h^0_j$ to various comm layers\n",
    "- Temporal recurrence: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity, obs_shape, action_shape, device):\n",
    "        self.capacity = capacity\n",
    "        self.obs = np.empty((capacity, *obs_shape), dtype=np.float32)\n",
    "        self.obs_next = np.empty((capacity, *obs_shape), dtype=np.float32)\n",
    "        self.actions = np.empty((capacity, *action_shape), dtype=np.float32)\n",
    "        self.rewards = np.empty((capacity, 1), dtype=np.float32)\n",
    "        self.not_dones = np.empty((capacity, 1), dtype=np.float32)\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.idx = 0\n",
    "        self.full = False\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.idx if not self.full else self.capacity\n",
    "    \n",
    "    def add(self, obs, actions, rewards, obs_next, not_done):\n",
    "        np.copyto(self.obs[self.idx], obs)\n",
    "        np.copyto(self.actions[self.idx], actions)\n",
    "        np.copyto(self.rewards[self.idx], rewards)\n",
    "        np.copyto(self.obs_next[self.idx], obs_next)\n",
    "        np.copyto(self.not_dones[self.idx], not_done)\n",
    "        \n",
    "        self.idx = (self.idx + 1) % self.capacity\n",
    "        self.full = self.full or self.idx == 0\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        idxs = np.random.randint(0,\n",
    "                                 self.capacity if self.full else self.idx,\n",
    "                                 size=batch_size)\n",
    "\n",
    "        obs = self.obs[idxs]\n",
    "        obs_next = self.obs_next[idxs]\n",
    "        \n",
    "        obs = torch.as_tensor(obs, device=self.device).float()\n",
    "        obs_next = torch.as_tensor(obs_next, device=self.device).float()\n",
    "        \n",
    "        actions = torch.as_tensor(self.actions[idxs], device=self.device)\n",
    "        rewards = torch.as_tensor(self.rewards[idxs], device=self.device)\n",
    "        \n",
    "        not_dones = torch.as_tensor(self.not_dones[idxs], device=self.device)\n",
    "        \n",
    "        return obs, actions, rewards, obs_next, not_dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, state_dim, h_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(state_dim, h_dim)\n",
    "        \n",
    "    def forward(self, s):\n",
    "        return F.relu(self.net(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_agents, h_dim, action_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h_dim = h_dim\n",
    "        self.action_dim = action_dim\n",
    "        \n",
    "        self.q = nn.Embedding(n_agents, h_dim * action_dim)\n",
    "    \n",
    "    def forward(self, h, agent_idx):\n",
    "        return torch.matmul(h, self.q(torch.tensor(agent_idx)).view(self.h_dim, self.action_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Module(nn.Module):\n",
    "#     \"\"\"Each agent has its own separate module. Paper specifies tanh() nonlinearities on output\"\"\"\n",
    "#     def __init__(self, h_dim, c_dim, n_layers, hidden_dim):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.H = nn.ModuleList([nn.Linear(h_dim, hidden_dim)])\n",
    "#         self.C = nn.ModuleList([nn.Linear(c_dim, hidden_dim)])\n",
    "        \n",
    "#         for _ in range(n_layers - 1):\n",
    "#             self.H.append(nn.ReLU())\n",
    "#             self.C.append(nn.ReLU())\n",
    "            \n",
    "#             self.H.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "#             self.C.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            \n",
    "#         self.H.append(nn.Linear(hidden_dim, h_dim))\n",
    "#         self.C.append(nn.Linear(hidden_dim, c_dim))\n",
    "        \n",
    "#     def forward(self, h, c):\n",
    "#         for layer in self.H:\n",
    "#             h = layer(h)\n",
    "            \n",
    "#         for layer in self.C:\n",
    "#             c = layer(c)\n",
    "            \n",
    "#         return torch.tanh(c + h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(nn.Module):\n",
    "    \"\"\"h_j^{i+1} = sigma(H^i h_j^i + C^i c_j^i)\n",
    "    \n",
    "        Each module contains all f_i for each agent\n",
    "    \"\"\"\n",
    "    def __init__(self, n_agents, h_dim, n_layers, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h_dim = h_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.H = nn.Embedding(num_embeddings=n_agents, embedding_dim=h_dim * hidden_dim)\n",
    "        self.C = nn.Embedding(num_embeddings=n_agents, embedding_dim=h_dim * hidden_dim)\n",
    "        \n",
    "        self.net = nn.ModuleList([nn.ReLU()])\n",
    "        \n",
    "        for _ in range(n_layers - 2):\n",
    "            self.net.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.net.append(nn.ReLU())\n",
    "            \n",
    "        self.net.append(nn.Linear(hidden_dim, h_dim))\n",
    "    \n",
    "    def grab_emb(self, agent_idx):\n",
    "        H = self.H(agent_idx)\n",
    "        C = self.C(agent_idx)\n",
    "        return H, C\n",
    "    \n",
    "    def forward(self, h, c, agent_idx):\n",
    "        H, C = self.grab_emb(torch.tensor(agent_idx))\n",
    "        \n",
    "        h = torch.matmul(h, H.view(self.h_dim, self.hidden_dim))\n",
    "        c = torch.matmul(c, C.view(self.h_dim, self.hidden_dim))\n",
    "        \n",
    "        hidden = h + c\n",
    "        \n",
    "        for layer in self.net:\n",
    "            hidden = layer(hidden)\n",
    "            \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommNetBase:\n",
    "    def __init__(self, state_dim, h_dim, c_dim, action_dim, hidden_dim, n_layers, n_agents,\n",
    "                 n_comm_steps, lr, batch_size, device):\n",
    "        \n",
    "        self.encoder = Encoder(state_dim, h_dim * n_agents).to(device)\n",
    "#         self.decoder = Decoder(h_dim * n_agents, action_dim * n_agents).to(device)\n",
    "        self.decoder = Decoder(n_agents, h_dim, action_dim).to(device)\n",
    "        \n",
    "        self.modules = []\n",
    "        \n",
    "        #f^i is shared across all agents\n",
    "        for k in range(n_comm_steps):\n",
    "            self.modules.append(\n",
    "                Module(n_agents, h_dim, n_layers, hidden_dim).to(device)\n",
    "            )\n",
    "\n",
    "        self.optim = Adam(\n",
    "            list(self.encoder.parameters()) + list(self.decoder.parameters()),\n",
    "            lr=lr\n",
    "        )\n",
    "        \n",
    "        for m in self.modules:\n",
    "            self.optim.add_param_group({'params': list(m.parameters())})\n",
    "            \n",
    "        self.n_comm_steps = n_comm_steps\n",
    "        self.n_agents = n_agents\n",
    "        self.c_dim = c_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def act(self, s, agent_idxs):\n",
    "        c_0 = torch.zeros(1, self.c_dim * self.n_agents).chunk(self.n_agents, dim=1)\n",
    "        h_0 = self.encoder(s).chunk(self.n_agents, dim=1)\n",
    "\n",
    "        all_k_hs = []\n",
    "        \n",
    "        for k in range(self.n_comm_steps):\n",
    "            step_k_hs = []\n",
    "            \n",
    "            for j in range(len(agent_idxs)):\n",
    "                if k == 0:\n",
    "                    h_j = self.modules[k](\n",
    "                        h_0[j], c_0[j], agent_idxs[j]\n",
    "                    )\n",
    "                    \n",
    "                    step_k_hs.append(h_j)\n",
    "                    \n",
    "                else:\n",
    "                    h_j = self.modules[k](\n",
    "                        all_k_hs[k - 1][j], comm_vectors[j], agent_idxs[j]\n",
    "                    )\n",
    "                    \n",
    "                    step_k_hs.append(h_j)\n",
    "            \n",
    "            all_k_hs.append(step_k_hs)\n",
    "            \n",
    "            comm_vectors = []\n",
    "            for j in range(len(agent_idxs)):\n",
    "                comm_vectors.append(self.h_to_c(step_k_hs, j, 1, len(agent_idxs)))\n",
    "\n",
    "#             for j in range(self.n_agents):\n",
    "#                 if k == 0:\n",
    "#                     h_j = self.modules[k](h_0[j], c_0[j])\n",
    "#                     step_k_hs.append(h_j)\n",
    "                    \n",
    "#                 else:\n",
    "#                     h_j = self.modules[k](all_k_hs[k - 1][j], comm_vectors[j])\n",
    "#                     step_k_hs.append(h_j)\n",
    "            \n",
    "#             all_k_hs.append(step_k_hs)\n",
    "            \n",
    "#             comm_vectors = []\n",
    "#             for j in range(self.n_agents):\n",
    "#                 comm_vectors.append(self.h_to_c(step_k_hs, j, 1))\n",
    "        \n",
    "        action_logits = []\n",
    "        for j in range(len(agent_idxs)):\n",
    "            action_logits.append(\n",
    "                self.decoder(all_k_hs[-1][j], agent_idxs[j])\n",
    "            )\n",
    "#         action_logits, q = self.decoder(torch.cat(all_k_hs[self.n_comm_steps - 1], dim=1))\n",
    "#         action_logits = action_logits.chunk(self.n_agents, dim=1)\n",
    "        actions = []\n",
    "        \n",
    "        for j in range(len(agent_idxs)):\n",
    "            actions.append(F.gumbel_softmax(action_logits[j], hard=True))\n",
    "        \n",
    "        return action_logits, actions\n",
    "            \n",
    "    def h_to_c(self, h, j, batch_size, n_agents):\n",
    "        \"\"\"h = [[batch_size, hidden_dim * 2], ... J]\n",
    "            j = what agent we care about\n",
    "        \"\"\"\n",
    "        sum_cntr = torch.zeros(batch_size, self.c_dim)\n",
    "\n",
    "        for agent in range(n_agents):\n",
    "            if agent == j:\n",
    "                continue\n",
    "            else:\n",
    "                sum_cntr += h[agent]\n",
    "                \n",
    "        sum_cntr /= (self.n_agents - 1)\n",
    "        \n",
    "        return sum_cntr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = CommNetBase(state_dim=64, h_dim=16, c_dim=16, action_dim=3, hidden_dim=64,\n",
    "            n_layers=3, n_agents=500, n_comm_steps=4, lr=0.01, batch_size=1, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[0.0091, 0.3712, 0.2957]], grad_fn=<MmBackward>),\n",
       "  tensor([[ 1.2547, -1.2044, -0.5666]], grad_fn=<MmBackward>),\n",
       "  tensor([[ 0.8637,  0.2336, -0.0886]], grad_fn=<MmBackward>)],\n",
       " [tensor([[0., 1., 0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[1., 0., 0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[1., 0., 0.]], grad_fn=<AddBackward0>)])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.act(torch.rand(1, 64), [1, 2, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
