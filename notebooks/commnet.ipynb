{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CommNet\n",
    "\n",
    "- Learning communication **not** with manually-specified protocols but instead using backpropagation from the RL signal\n",
    "- Considers cooperative task between $J$ agents.\n",
    "- Can be viewed as a single large model\n",
    "\n",
    "Given a view of the state for all agents $s = \\{s_1,...,s_J\\}$, a controller maps states to actions $a = \\Phi(s)$ where $a = \\{a_1,...,a_J\\}$ is a concatenation of discrete actions.\n",
    "\n",
    "$\\Phi$ is made of modules $f^i$, whic are multi-layer neural networks. $i \\in \\{0,..,K\\}$ is the number of communication steps in the network.\n",
    "\n",
    "Each $f^i$ takes two input vectors for each agent $j$: hidden state $h^i_j$ and communication $c^i_j$ and outputs a vector $h_j^{i+1}$. In the case that $f$ is a single-layer nn, $h^{i+1}_j = \\sigma(C^i_j c^i_j + H^i_j h^i_j)$.\n",
    "\n",
    "First layer of NN is an encoder function $h^0_j = r(s_j)$. For most tasks, they say it is a single-layer NN. \n",
    "\n",
    "$c^0_j$ = 0 âˆ€ j$.\n",
    "\n",
    "Output of NN is a decoder $a_j \\sim q(h^K_j)$ that outputs a distribution oer the action space. Single layer NN with softmax output. \n",
    "\n",
    "## Variations\n",
    "- Only allow communication between agents within a certain range.\n",
    "- Create skip connection between input encoding $h^0_j$ to various comm layers\n",
    "- Temporal recurrence: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity, obs_shape, action_shape, device):\n",
    "        self.capacity = capacity\n",
    "        self.obs = np.empty((capacity, *obs_shape), dtype=np.float32)\n",
    "        self.obs_next = np.empty((capacity, *obs_shape), dtype=np.float32)\n",
    "        self.actions = np.empty((capacity, *action_shape), dtype=np.float32)\n",
    "        self.rewards = np.empty((capacity, 1), dtype=np.float32)\n",
    "        self.not_dones = np.empty((capacity, 1), dtype=np.float32)\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.idx = 0\n",
    "        self.full = False\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.idx if not self.full else self.capacity\n",
    "    \n",
    "    def add(self, obs, actions, rewards, obs_next, not_done):\n",
    "        np.copyto(self.obs[self.idx], obs)\n",
    "        np.copyto(self.actions[self.idx], actions)\n",
    "        np.copyto(self.rewards[self.idx], rewards)\n",
    "        np.copyto(self.obs_next[self.idx], obs_next)\n",
    "        np.copyto(self.not_dones[self.idx], not_done)\n",
    "        \n",
    "        self.idx = (self.idx + 1) % self.capacity\n",
    "        self.full = self.full or self.idx == 0\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        idxs = np.random.randint(0,\n",
    "                                 self.capacity if self.full else self.idx,\n",
    "                                 size=batch_size)\n",
    "\n",
    "        obs = self.obs[idxs]\n",
    "        obs_next = self.obs_next[idxs]\n",
    "        \n",
    "        obs = torch.as_tensor(obs, device=self.device).float()\n",
    "        obs_next = torch.as_tensor(obs_next, device=self.device).float()\n",
    "        \n",
    "        actions = torch.as_tensor(self.actions[idxs], device=self.device)\n",
    "        rewards = torch.as_tensor(self.rewards[idxs], device=self.device)\n",
    "        \n",
    "        not_dones = torch.as_tensor(self.not_dones[idxs], device=self.device)\n",
    "        \n",
    "        return obs, actions, rewards, obs_next, not_dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, state_dim, h_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(state_dim, h_dim)\n",
    "        \n",
    "    def forward(self, s):\n",
    "        return F.relu(self.net(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, h_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(h_dim, action_dim)\n",
    "        \n",
    "        self.q = nn.Linear(h_dim, 1)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        return self.net(h), self.q(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(nn.Module):\n",
    "    \"\"\"Each agent has its own separate module. Paper specifies tanh() nonlinearities on output\"\"\"\n",
    "    def __init__(self, h_dim, c_dim, n_layers, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.H = nn.ModuleList([nn.Linear(h_dim, hidden_dim)])\n",
    "        self.C = nn.ModuleList([nn.Linear(c_dim, hidden_dim)])\n",
    "        \n",
    "        for _ in range(n_layers - 1):\n",
    "            self.H.append(nn.ReLU())\n",
    "            self.C.append(nn.ReLU())\n",
    "            \n",
    "            self.H.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.C.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            \n",
    "        self.H.append(nn.Linear(hidden_dim, h_dim))\n",
    "        self.C.append(nn.Linear(hidden_dim, c_dim))\n",
    "        \n",
    "    def forward(self, h, c):\n",
    "        for layer in self.H:\n",
    "            h = layer(h)\n",
    "            \n",
    "        for layer in self.C:\n",
    "            c = layer(c)\n",
    "            \n",
    "        return torch.tanh(c + h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommNetBase:\n",
    "    def __init__(self, state_dim, h_dim, c_dim, action_dim, hidden_dim, n_layers, n_agents,\n",
    "                 n_comm_steps, lr, batch_size, device):\n",
    "        \n",
    "        self.encoder = Encoder(state_dim, h_dim * n_agents).to(device)\n",
    "        self.decoder = Decoder(h_dim * n_agents, action_dim * n_agents).to(device)\n",
    "        \n",
    "        self.modules = []\n",
    "        \n",
    "        #f^i is shared across all agents\n",
    "        for k in range(n_comm_steps):\n",
    "            self.modules.append(\n",
    "                Module(h_dim, c_dim, n_layers, hidden_dim).to(device)\n",
    "            )\n",
    "\n",
    "        self.optim = Adam(\n",
    "            list(self.encoder.parameters()) + list(self.decoder.parameters()),\n",
    "            lr=lr\n",
    "        )\n",
    "        \n",
    "        for m in self.modules:\n",
    "            self.optim.add_param_group({'params': list(m.parameters())})\n",
    "            \n",
    "        self.n_comm_steps = n_comm_steps\n",
    "        self.n_agents = n_agents\n",
    "        self.c_dim = c_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def act(self, s):\n",
    "        c_0 = torch.zeros(1, self.c_dim * self.n_agents).chunk(self.n_agents, dim=1)\n",
    "        h_0 = self.encoder(s).chunk(self.n_agents, dim=1)\n",
    "\n",
    "        all_k_hs = []\n",
    "        \n",
    "        for k in range(self.n_comm_steps):\n",
    "            step_k_hs = []\n",
    "            \n",
    "            for j in range(self.n_agents):\n",
    "                if k == 0:\n",
    "                    h_j = self.modules[k](h_0[j], c_0[j])\n",
    "                    step_k_hs.append(h_j)\n",
    "                    \n",
    "                else:\n",
    "                    h_j = self.modules[k](all_k_hs[k - 1][j], comm_vectors[j])\n",
    "                    step_k_hs.append(h_j)\n",
    "            \n",
    "            all_k_hs.append(step_k_hs)\n",
    "            \n",
    "            comm_vectors = []\n",
    "            for j in range(self.n_agents):\n",
    "                comm_vectors.append(self.h_to_c(step_k_hs, j, 1))\n",
    "\n",
    "        action_logits, q = self.decoder(torch.cat(all_k_hs[self.n_comm_steps - 1], dim=1))\n",
    "        action_logits = action_logits.chunk(self.n_agents, dim=1)\n",
    "        actions = []\n",
    "        \n",
    "        for k in range(self.n_agents):\n",
    "            actions.append(F.gumbel_softmax(action_logits[k], hard=True))\n",
    "        \n",
    "        return actions, q\n",
    "            \n",
    "    def h_to_c(self, h, j, batch_size):\n",
    "        \"\"\"h = [[batch_size, hidden_dim * 2], ... J]\n",
    "            j = what agent we care about\n",
    "        \"\"\"\n",
    "        sum_cntr = torch.zeros(batch_size, self.c_dim)\n",
    "\n",
    "        for agent in range(self.n_agents):\n",
    "            if agent == j:\n",
    "                continue\n",
    "            else:\n",
    "                sum_cntr += h[agent]\n",
    "                \n",
    "        sum_cntr /= (self.n_agents - 1)\n",
    "        \n",
    "        return sum_cntr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = CommNetBase(state_dim=64, h_dim=16, c_dim=16, action_dim=3, hidden_dim=64,\n",
    "            n_layers=3, n_agents=4, n_comm_steps=4, lr=0.01, batch_size=1, device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
